# ğŸš€ GitHub toolkit

A Python-based web scraper that collects GitHub developer information, their followers, and repository details using Selenium and stores the data in a MySQL database.

## âœ¨ Features

- ğŸ”¥ Scrapes trending developers across multiple programming languages
- ğŸ‘¥ Collects follower information (up to 1000 per developer)
- ğŸ“¦ Gathers repository details including name, URL, description, language, stars, and forks
- ğŸ” Supports authentication via cookies or username/password
- ğŸ—„ï¸ Stores data in a MySQL database with automatic schema creation
- âš ï¸ Includes error handling and logging
- ğŸ§© Follows clean architecture principles

## ğŸ—‚ï¸ Project Structure

```
github-toolkit/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py           # Configuration and environment variables
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ entities.py          # Domain entities
â”‚   â””â”€â”€ exceptions.py        # Custom exceptions
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ database/           # Database-related code
â”‚   â”‚   â”œâ”€â”€ connection.py
â”‚   â”‚   â””â”€â”€ models.py
â”‚   â””â”€â”€ auth/              # Authentication service
â”‚       â””â”€â”€ auth_service.py
â”œâ”€â”€ services/
â”‚   â””â”€â”€ scraping/          # Scraping services
â”‚       â”œâ”€â”€ github_developer_scraper.py
â”‚       â””â”€â”€ github_repo_scraper.py
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ helpers.py         # Utility functions
â”œâ”€â”€ controllers/
â”‚   â””â”€â”€ github_scraper_controller.py  # Main controller
â”œâ”€â”€ main.py                # Entry point
â””â”€â”€ README.md
```

## ğŸ› ï¸ Prerequisites

- ğŸ Python 3.8+
- ğŸ—„ï¸ MySQL database
- ğŸŒ Chrome browser
- ğŸ§° Chrome WebDriver

## âš™ï¸ Installation

1. Clone the repository:
```bash
git clone git@github.com:trinhminhtriet/github-toolkit.git
cd github-toolkit
```

2. Create a virtual environment and activate it:
```bash
python -m venv .venv
source .venv/bin/activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Create a `.env` file in the root directory with the following variables:
```
GITHUB_USERNAME=your_username
GITHUB_PASSWORD=your_password
DB_USERNAME=your_db_username
DB_PASSWORD=your_db_password
DB_HOST=your_db_host
DB_NAME=your_db_name
```

5. Create a `config` directory:
```bash
mkdir config
```

## ğŸ“‹ Requirements

Create a `requirements.txt` file with:
```
selenium
sqlalchemy
python-dotenv
```

## â–¶ï¸ Usage

Run the scraper:
```bash
cd src
python main.py
```

The scraper will:
1. ğŸ”‘ Authenticate with GitHub
2. ğŸŒŸ Scrape trending developers for specified languages
3. ğŸ‘¥ Collect their followers (up to 1000 per developer)
4. ğŸ“¦ Scrape their repositories
5. ğŸ’¾ Store all data in the MySQL database

## âš™ï¸ Configuration

- Modify `config/settings.py` to change:
  - `LANGUAGES`: List of programming languages to scrape
  - `USE_COOKIE`: Toggle between cookie-based and credential-based authentication
- â±ï¸ Adjust sleep times in services if needed for rate limiting

## ğŸ—ƒï¸ Database Schema

### github_users
- ğŸ†” id (PK)
- ğŸ‘¤ username (unique)
- ğŸ”— profile_url
- ğŸ•’ created_at
- ğŸ•’ updated_at
- ğŸ“… published_at

### github_repos
- ğŸ†” id (PK)
- ğŸ‘¤ username
- ğŸ“¦ repo_name
- ğŸ“ repo_intro
- ğŸ”— repo_url (unique)
- ğŸ·ï¸ repo_lang
- â­ repo_stars
- ğŸ´ repo_forks
- ğŸ•’ created_at
- ğŸ•’ updated_at
- ğŸ“… published_at

## ğŸ›¡ï¸ Error Handling

- â— Custom exceptions for authentication, scraping, and database operations
- ğŸ“ Logging configured at INFO level
- ğŸ›‘ Graceful shutdown of browser instance

## ğŸ¤ Contributing

1. Fork the repository.
2. Create a feature branch (`git checkout -b feature/your-feature`).
3. Commit changes (`git commit -m "Add your feature"`).
4. Push to the branch (`git push origin feature/your-feature`).
5. Open a pull request.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details (create one if needed).

## ğŸ™ Acknowledgments

- Built with [Selenium](https://www.selenium.dev/), [SQLAlchemy](https://www.sqlalchemy.org/), and [Python](https://www.python.org/).
- Inspired by the need to automate GitHub data collection.